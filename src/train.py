#!/usr/bin/env python
"""
BERT fine-tune CLI â€“ zero-crash across any ğŸ¤— Transformers
========================================================
è¨“ç·´ä¸€å€‹ä¸­æ–‡åºåˆ—åˆ†é¡æ¨¡å‹ï¼Œæ­¤æ¨¡å‹åŸºæ–¼ä¸€å€‹å·²ç¶“ tokenized çš„
`DatasetDict` (é€é `save_to_disk` å„²å­˜)ã€‚

ä¸»è¦è¨­è¨ˆ
----------
* **ç°½åæ„ŸçŸ¥ (Signature-aware) çš„ TrainingArguments** â€“ æ¯å€‹é—œéµå­—åƒæ•¸éƒ½æœƒ
    æ ¹æ“šæ‚¨ *å·²å®‰è£* çš„ Transformers ç‰ˆæœ¬é€²è¡Œéæ¿¾ã€‚
* **è‡ªå‹•å°é½Šç­–ç•¥** â€“ è‡ªå‹•å”èª¿ `evaluation_strategy` (`eval_strategy`),
    `save_strategy`, å’Œ `load_best_model_at_end` ä»¥é¿å…æ’ç¨‹å™¨ä¸åŒ¹é…çš„éŒ¯èª¤ã€‚
* **æ”¯æ´å¿«é€Ÿå­é›†æŠ½æ¨£** â€“ å¯ä½¿ç”¨ `--rows N` æˆ– `start-end` æ ¼å¼ã€‚
* **è‡ªå‹•è½‰æ›æ¨™ç±¤** â€“ å°‡åˆ—è¡¨å½¢å¼çš„æ¨™ç±¤ï¼ˆå¦‚ `[1]`ï¼‰è‡ªå‹•è½‰æ›ç‚ºç´”é‡ï¼ˆ`1`ï¼‰ã€‚
* **å¯é¸çš„ Weights & Biases æ—¥èªŒ** (`--no_wandb`)ã€‚

ç¯„ä¾‹
-------
```bash
python train.py -d data_cache_v2 -o ckpt --rows 5000 \
  --project myproj --run debug-5k
```
"""
from __future__ import annotations

import argparse
import logging
import math
import re
from inspect import signature
from pathlib import Path
from typing import Tuple

import pandas as pd
from datasets import Dataset, DatasetDict, load_from_disk
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    DataCollatorWithPadding,
    Trainer,
    TrainingArguments,
)

try:
    import wandb
except ImportError:
    wandb = None

# è¨­å®šæ—¥èªŒè¨˜éŒ„å™¨
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)

# ---------------------------------------------------------------------------
# TrainingArguments å»ºæ§‹å™¨ â€“ ç‰ˆæœ¬å…¼å®¹ä¸”ç­–ç•¥ä¸€è‡´
# ---------------------------------------------------------------------------

def build_training_args(
    *,
    out_dir: Path,
    steps_per_epoch: int,
    warmup_steps: int,
    batch_size: int,
    grad_accum: int,
    epochs: int,
    use_wandb: bool,
) -> TrainingArguments:
    """
    å»ºç«‹ä¸€å€‹ç­–ç•¥ä¸€è‡´ä¸”å°ä¸åŒ transformers ç‰ˆæœ¬å…¼å®¹çš„ TrainingArguments ç‰©ä»¶ã€‚
    """
    base_args = {
        "output_dir": str(out_dir),
        "overwrite_output_dir": True,
        "num_train_epochs": epochs,
        "per_device_train_batch_size": batch_size,
        "per_device_eval_batch_size": batch_size * 2,
        "gradient_accumulation_steps": grad_accum,
        "learning_rate": 2e-5,
        "warmup_steps": warmup_steps,
        "weight_decay": 0.01,
        "logging_strategy": "steps",
        "logging_steps": max(1, steps_per_epoch // 10),
        "save_strategy": "epoch",
        "load_best_model_at_end": True,
        "metric_for_best_model": "eval_loss",
        "greater_is_better": False,
        "fp16": True,
        "seed": 42,
        "dataloader_num_workers": 4,
        "report_to": ["wandb"] if use_wandb else [],
        "lr_scheduler_type": "linear",
    }

    sig = signature(TrainingArguments).parameters
    if "evaluation_strategy" in sig:
        base_args["evaluation_strategy"] = "epoch"
    elif "eval_strategy" in sig:
        base_args["eval_strategy"] = "epoch"

    supported_args = {k: v for k, v in base_args.items() if k in sig}
    
    logging.info(f"ä½¿ç”¨çš„è©•ä¼°ç­–ç•¥åƒæ•¸: {'evaluation_strategy' if 'evaluation_strategy' in supported_args else 'eval_strategy'}")

    return TrainingArguments(**supported_args)


# ---------------------------------------------------------------------------
# ä¸»åŸ·è¡Œæµç¨‹é¡åˆ¥
# ---------------------------------------------------------------------------

class BertTrainer:
    def __init__(self, args: argparse.Namespace):
        self.args = args
        self.use_wandb = not args.no_wandb and (wandb is not None)

    def run(self):
        """åŸ·è¡Œå®Œæ•´çš„è¨“ç·´æµç¨‹"""
        self.init_wandb()
        ds_dict = self.prepare_dataset()

        tokenizer = AutoTokenizer.from_pretrained(self.args.model, use_fast=True)
        model = AutoModelForSequenceClassification.from_pretrained(
            self.args.model,
            num_labels=self.args.num_labels,
            hidden_dropout_prob=0.3,
            torch_dtype="auto",
            gradient_checkpointing=True,
        )
        
        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
        
        num_train_rows = len(ds_dict["train"])
        steps_per_epoch = math.ceil(num_train_rows / (self.args.batch_size * self.args.grad_accum))
        total_train_steps = steps_per_epoch * self.args.epochs
        warmup_steps = int(0.1 * total_train_steps)

        training_args = build_training_args(
            out_dir=self.args.output_dir,
            steps_per_epoch=steps_per_epoch,
            warmup_steps=warmup_steps,
            batch_size=self.args.batch_size,
            grad_accum=self.args.grad_accum,
            epochs=self.args.epochs,
            use_wandb=self.use_wandb,
        )

        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=ds_dict["train"],
            eval_dataset=ds_dict["validation"],
            tokenizer=tokenizer,
            data_collator=data_collator,
        )
        
        logging.info("é–‹å§‹æ¨¡å‹è¨“ç·´...")
        trainer.train()
        logging.info("æ¨¡å‹è¨“ç·´å®Œæˆã€‚")

        if self.use_wandb:
            wandb.finish()

    def init_wandb(self):
        if self.use_wandb:
            logging.info(f"åˆå§‹åŒ– Weights & Biases: project='{self.args.project}', run='{self.args.run}'")
            wandb.init(project=self.args.project, name=self.args.run, save_code=True)

    def prepare_dataset(self) -> DatasetDict:
        """è¼‰å…¥ã€ä¿®æ­£ã€æŠ½æ¨£å’Œé©—è­‰è³‡æ–™é›†"""
        logging.info(f"å¾ {self.args.dataset_dir} è¼‰å…¥è³‡æ–™é›†...")
        ds_dict = load_from_disk(str(self.args.dataset_dir))

        # --- æ–°å¢çš„ä¿®æ­£ (é—œéµ) ---
        # æª¢æŸ¥ä¸¦ä¿®æ­£å¯èƒ½å­˜åœ¨çš„éåº¦å·¢ç‹€åŒ–ç‰¹å¾µ (ä¾‹å¦‚ [[...]] -> [...])
        def unnest_features(example):
            for key in ['input_ids', 'attention_mask', 'token_type_ids']:
                if key in example and isinstance(example[key], list) and len(example[key]) > 0 and isinstance(example[key][0], list):
                    example[key] = example[key][0]
            return example

        for split in ds_dict.keys():
            # æª¢æŸ¥ç¬¬ä¸€å€‹æ¨£æœ¬ä¾†åˆ¤æ–·æ˜¯å¦éœ€è¦ä¿®æ­£
            first_item = ds_dict[split][0]
            if 'input_ids' in first_item and isinstance(first_item['input_ids'], list) and len(first_item['input_ids']) > 0 and isinstance(first_item['input_ids'][0], list):
                 logging.info(f"åµæ¸¬åˆ° '{split}' è³‡æ–™é›†ä¸­æœ‰å·¢ç‹€ç‰¹å¾µï¼Œæ­£åœ¨é€²è¡Œå³æ™‚ä¿®æ­£...")
                 ds_dict[split] = ds_dict[split].map(unnest_features, num_proc=4)

        if self.args.rows:
            ds_dict["train"] = self._subset(ds_dict["train"], self.args.rows)
            logging.info(f"å·²æŠ½æ¨£è¨“ç·´é›†ï¼Œä½¿ç”¨å‰ {len(ds_dict['train']):,} ç­†è³‡æ–™ã€‚")

        for split in ("train", "validation"):
            if split in ds_dict:
                ds_dict[split] = self._squeeze_label(ds_dict[split], split_name=split)

        self._sanity_check(ds_dict, self.args.num_labels)
        return ds_dict

    def _parse_rows(self, spec: str) -> Tuple[int, int]:
        if re.fullmatch(r"\d+", spec):
            return 0, int(spec)
        m = re.fullmatch(r"(\d+)-(\d+)", spec)
        if not m:
            raise ValueError("--rows éœ€è¦æ˜¯ N æˆ– start-end æ ¼å¼ (ä¾‹å¦‚ 5000 æˆ– 1000-14999)")
        a, b = map(int, m.groups())
        if b < a:
            raise ValueError("--rows çš„çµæŸå€¼ä¸èƒ½å°æ–¼èµ·å§‹å€¼")
        return a, b + 1

    def _subset(self, ds: Dataset, spec: str | None) -> Dataset:
        if spec is None:
            return ds
        s, e = self._parse_rows(spec)
        return ds.select(range(s, min(e, len(ds))))

    def _squeeze_label(self, ds: Dataset, split_name: str) -> Dataset:
        if ds and isinstance(ds[0]["labels"], list):
            def fn(ex):
                uniq_labels = set(ex["labels"])
                if len(uniq_labels) != 1:
                    raise ValueError(f"ç™¼ç¾å¤šæ¨™ç±¤ç¯„ä¾‹: {ex['labels']}")
                ex["labels"] = ex["labels"][0]
                return ex
            logging.info(f"æ­£åœ¨è½‰æ› '{split_name}' çš„æ¨™ç±¤æ ¼å¼...")
            ds = ds.map(fn, num_proc=4)
        return ds

    def _sanity_check(self, dd: DatasetDict, num_labels: int):
        required_cols = {"input_ids", "attention_mask", "labels"}
        for split, dset in dd.items():
            if missing_cols := required_cols - set(dset.column_names):
                raise ValueError(f"è³‡æ–™é›† '{split}' ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}")
            
            labels = pd.Series(dset["labels"])
            if not labels.isin(range(num_labels)).all():
                raise ValueError(f"è³‡æ–™é›† '{split}' çš„æ¨™ç±¤å¿…é ˆåœ¨ 0 åˆ° {num_labels-1} ä¹‹é–“")
            
            dist_str = labels.value_counts().sort_index().to_dict()
            logging.info(f"{split}: {len(dset):,} ç­†, æ¨™ç±¤åˆ†ä½ˆ={dist_str}")


def main():
    p = argparse.ArgumentParser(
        description="ä¸€å€‹èƒ½å…¼å®¹ä¸åŒç‰ˆæœ¬ Transformers çš„ BERT å¾®èª¿è…³æœ¬ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    p.add_argument("-d", "--dataset_dir", required=True, type=Path, help="å·²å„²å­˜çš„ DatasetDict è³‡æ–™å¤¾è·¯å¾‘")
    p.add_argument("-o", "--output_dir", required=True, type=Path, help="æ¨¡å‹æª¢æŸ¥é»å’Œè¼¸å‡ºçš„å„²å­˜è·¯å¾‘")
    p.add_argument("--rows", type=str, help="æŠ½æ¨£è¨“ç·´é›†ï¼Œå¯ç‚ºæ•¸å­— N æˆ– 'start-end' å€é–“")
    p.add_argument("--num_labels", type=int, default=3, help="åˆ†é¡ä»»å‹™çš„æ¨™ç±¤æ•¸é‡")
    p.add_argument("--batch_size", type=int, default=32, help="æ¯å€‹è¨­å‚™çš„è¨“ç·´æ‰¹æ¬¡å¤§å°")
    p.add_argument("--grad_accum", type=int, default=2, help="æ¢¯åº¦ç´¯ç©æ­¥æ•¸")
    p.add_argument("--epochs", type=int, default=3, help="ç¸½è¨“ç·´è¼ªæ•¸")
    p.add_argument("--project", default="bert-project", help="Weights & Biases çš„å°ˆæ¡ˆåç¨±")
    p.add_argument("--run", default="run-1", help="Weights & Biases çš„é‹è¡Œåç¨±")
    p.add_argument("--no_wandb", action="store_true", help="åœç”¨ Weights & Biases æ—¥èªŒè¨˜éŒ„")
    p.add_argument("--model", default="ckiplab/bert-base-chinese", help="è¦ä½¿ç”¨çš„é è¨“ç·´æ¨¡å‹åç¨±")
    
    args = p.parse_args()
    
    trainer = BertTrainer(args)
    trainer.run()


if __name__ == "__main__":
    main()
